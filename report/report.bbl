\begin{thebibliography}{10}

\bibitem{chen2021randomized}
Xue~Bin Chen, Tongzheng Lu, Xinyue Xu, Zichuan Zhu, Yuxin Yang, Zuyuan Ma, Heng Xu, and Yuan Zhu.
\newblock Randomized ensembled double q-learning: Learning fast without a model.
\newblock In {\em International Conference on Learning Representations}, 2021.

\bibitem{dosovitskiy2017carla}
Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio Lopez, and Vladlen Koltun.
\newblock {CARLA}: An open urban driving simulator.
\newblock In {\em Proceedings of the 1st Annual Conference on Robot Learning}, pages 1--16, 2017.

\bibitem{fu2020d4rl}
Justin Fu, Aviral Kumar, Ofir Nachum, George Tucker, and Sergey Levine.
\newblock D4rl: Datasets for deep data-driven reinforcement learning.
\newblock {\em arXiv preprint arXiv:2004.07219}, 2020.

\bibitem{fujimoto2018td3}
Scott Fujimoto, Herke van Hoof, and David Meger.
\newblock Addressing function approximation error in actor-critic methods.
\newblock In {\em International Conference on Machine Learning}, pages 1587--1596, 2018.

\bibitem{haarnoja2018soft}
Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, and Sergey Levine.
\newblock Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor.
\newblock In {\em International Conference on Machine Learning}, 2018.

\bibitem{kumar2020conservative}
Aviral Kumar, Aurick Zhou, George Tucker, and Sergey Levine.
\newblock Conservative q-learning for offline reinforcement learning.
\newblock In {\em Advances in Neural Information Processing Systems}, volume~33, pages 1179--1191, 2020.

\bibitem{kuznetsov2020controlling}
Arsenii Kuznetsov, Pavel Shvechikov, Alexander Grishin, and Dmitry Vetrov.
\newblock Controlling overestimation bias with truncated mixture of continuous distributional quantile critics.
\newblock In {\em International Conference on Machine Learning}, 2020.

\bibitem{tmrl2022}
Yannick Li{\'e}geois.
\newblock Trackmania roborace league.
\newblock \url{https://github.com/trackmania-rl/tmrl}, 2022.

\bibitem{lillicrap2016ddpg}
Timothy~P. Lillicrap, Jonathan~J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra.
\newblock Continuous control with deep reinforcement learning.
\newblock In {\em International Conference on Learning Representations}, 2016.

\bibitem{mnih2015human}
Volodymyr Mnih, Koray Kavukcuoglu, David Silver, et~al.
\newblock Human-level control through deep reinforcement learning.
\newblock {\em Nature}, 518(7540):529--533, 2015.

\bibitem{siméoni2025dinov3}
Oriane Siméoni, Huy~V. Vo, Maximilian Seitzer, Federico Baldassarre, Maxime Oquab, Cijo Jose, Vasil Khalidov, Marc Szafraniec, Seungeun Yi, Michaël Ramamonjisoa, Francisco Massa, Daniel Haziza, Luca Wehrstedt, Jianyuan Wang, Timothée Darcet, Théo Moutakanni, Leonel Sentana, Claire Roberts, Andrea Vedaldi, Jamie Tolan, John Brandt, Camille Couprie, Julien Mairal, Hervé Jégou, Patrick Labatut, and Piotr Bojanowski.
\newblock Dinov3, 2025.

\bibitem{trumpp2025impoolapoweraveragepooling}
Raphael Trumpp, Ansgar Schäfftlein, Mirco Theile, and Marco Caccamo.
\newblock Impoola: The power of average pooling for image-based deep reinforcement learning, 2025.

\end{thebibliography}
